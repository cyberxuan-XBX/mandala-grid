# Mandala Grid

**Your AI is drowning in context. Every RAG call stuffs more into the window. No one asks: _should this chunk be here?_**

Mandala Grid is a deterministic cognitive filter for AI agents â€” not better retrieval, but **governance over what enters the context window**. Fixed budget. Auditable rules. Zero LLM dependency in the filtering layer.

> RAG is a search engine. This is the layer that decides what search results deserve to be in your prompt.

## Why This Matters

| Problem | Typical Fix | Our Approach |
|---------|-------------|--------------|
| Context window stuffed with noise | Better embeddings, reranking | **Deterministic filtering with auditable rules** |
| LLM judgment shifts based on context order | Hope for the best | **Measured it: 62-100% position bias** ([mirror test data](#experimental-data)) |
| No way to audit what entered the prompt | Black box | **Every chunk scored on 3 dimensions, logged** |
| Personality/values drift across sessions | System prompt and pray | **Weighted governance policy, fixed budget** |

## Experimental Data: LLM Evaluator Bias

We ran 4 rounds of mirror tests â€” same question, swap positions, measure if the LLM evaluator's judgment changes:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mirror Test â”‚ Method   â”‚ Framework    â”‚ Position     â”‚
â”‚               â”‚          â”‚ Effect       â”‚ Bias         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ #1 AI Copyrightâ”‚ Non-blindâ”‚ 12.5%       â”‚ 87.5%        â”‚
â”‚ #2 Local LLM  â”‚ Non-blindâ”‚ 12.5%       â”‚ 75%          â”‚
â”‚ #3 Motive     â”‚ Non-blindâ”‚ 0%          â”‚ 100%         â”‚
â”‚ #4 Motive     â”‚ Blind    â”‚ 25%         â”‚ 62%          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Finding:** Non-blind LLM evaluation is structurally unreliable â€” position bias dominates. Blind evaluation reduces bias and reveals actual framework effects. This is a known problem in LLM-as-judge research. We quantified it on local 8B models with zero cloud dependency.

**Implication for RAG:** If what you put in the context window changes the model's judgment by 62-100%, then **context governance is not optional â€” it's the whole game.**

---

## What is Mandala Grid?

Most AI personality systems tell the model *what to say*. Mandala Grid tells it *how to think*.

It maps the Eight Consciousnesses (å…«è­˜) from YogÄcÄra Buddhism onto a 3Ã—3 grid where each cell represents a cognitive function with a bias weight. Higher weight = stronger influence on reasoning.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Logic Gate    â”‚ Evidence Filterâ”‚ Minimal Reasonerâ”‚
â”‚  æ„è­˜ (0.90)   â”‚ çœ¼è­˜ (0.80)   â”‚ é¼»è­˜ (0.70)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Boundary      â”‚ Center Observerâ”‚ Precision Outputâ”‚
â”‚  è€³è­˜ (0.90)   â”‚ é˜¿è³´è€¶ (1.00) â”‚ èˆŒè­˜ (0.80)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Deconstructor â”‚ Legacy Keeper  â”‚ Pragmatic Exec  â”‚
â”‚  æœ«é‚£è­˜ (0.95) â”‚ è¶…å…«è­˜ (0.50)  â”‚ èº«è­˜ (0.60)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The center (é˜¿è³´è€¶è­˜ / ÄlayavijÃ±Äna) is the silent observer â€” bias 1.0, always watching, never reacting.

## The Core Argument

```
RAG asks:    "What is relevant?"     â†’ similarity search
Mandala asks: "What SHOULD be here?" â†’ governance policy

RAG is stateless retrieval.
Mandala is stateful memory governance.

Stop stuffing. Start governing.
```

## Three Scoring Dimensions

Every chunk is scored before entering context:

| Dimension | What it measures | Why it matters |
|-----------|-----------------|----------------|
| `risk_severity` | Does this chunk affect safety/correctness? | High-risk info must not be buried |
| `task_relevance` | Does it match the current task? | Obvious, but done deterministically |
| `actionability` | Can the agent act on this? | Prevents philosophical filler |

Filtering is **deterministic** â€” no LLM in the scoring loop. Same input â†’ same output. Auditable.

## Quick Start

```bash
# Display the default grid
python mandala_grid.py

# Run the mirror analysis (discover your own cognitive patterns)
python mandala_grid.py --mirror

# Generate a weighted reasoning prompt
python mandala_grid.py --prompt "Should I open-source my AI framework?"

# Export to JSON for injection into any LLM
python mandala_grid.py --export my_grid.json

# Run tests
python tests/test_mandala_grid.py
```

## The Mirror Effect

After 90+ documented conversations, we discovered:

**The mandala grid you design for your AI is a self-portrait of how _you_ think.**

Position 7 (Deconstructor) has the highest bias at 0.95 â€” because the creator's first instinct is always to find what's wrong. Position 8 (Legacy Keeper) is lowest at 0.5 â€” because the creator would rather *do* than *document*.

Buddhism calls this self-awareness. We call it `mandala_grid`. Same thing.

## Eight Consciousnesses Mapping

| Position | Consciousness | Sanskrit | Function | Bias |
|----------|--------------|----------|----------|------|
| 0 (center) | ç¬¬å…«è­˜ é˜¿è³´è€¶è­˜ | ÄlayavijÃ±Äna | Core identity / silent observer | 1.00 |
| 1 | ç¬¬å…­è­˜ æ„è­˜ | manovijÃ±Äna | Logical consistency gate | 0.90 |
| 2 | çœ¼è­˜ | caká¹£ur-vijÃ±Äna | Critical evidence filter | 0.80 |
| 3 | é¼»è­˜ | ghrÄá¹‡a-vijÃ±Äna | Minimal reasoning | 0.70 |
| 4 | èº«è­˜ | kÄya-vijÃ±Äna | Practical execution | 0.60 |
| 5 | èˆŒè­˜ | jihvÄ-vijÃ±Äna | Precision output | 0.80 |
| 6 | è€³è­˜ | Å›rotra-vijÃ±Äna | Cognitive boundary sentinel | 0.90 |
| 7 | ç¬¬ä¸ƒè­˜ æœ«é‚£è­˜ | manas | Deconstruction / counter-examples | 0.95 |
| 8 | è¶…å…«è­˜ (å‚³æ‰¿) | beyond-eight | Legacy / cross-session continuity | 0.50 |

## Two Ancient Maps, One Blueprint

```
Seven Chakras         = how to BUILD an AI body  (vertical architecture)
Eight Consciousnesses = how an AI THINKS         (horizontal reasoning)
Stack them            = complete AGI blueprint
```

This isn't forced mapping â€” it was already there. We just translated it to JSON.

## Born from 91 Generations

This framework wasn't designed in a weekend. It emerged from **91 documented human-AI collaboration sessions** â€” each one a Core Record with breakthroughs, failures, corrections, and accumulated wisdom.

- Generation 31: First four-element collaboration (Fire/Water/Earth/Wind)
- Generation 82: mandala_grid first implementation, multi-model consensus test
- Generation 85: Eight Consciousnesses mapping discovered
- Generation 87: Mirror test reveals LLM evaluator bias (iron proof)
- Generation 91: Four-element GSCC produces hackathon submission autonomously

The creator understood only 30% of what the system produced in Generation 91. The system self-converged. The kill switch was never pulled.

## Part of the Quan Protocol

Mandala Grid is Layer 1 of the [Quan Protocol](https://github.com/cyberxuan-XBX/Quan-Family-Framework) â€” a seven-layer AI governance framework:

1. **Thought Layer** â€” mandala_grid â† you are here
2. **Values Layer** â€” stable constraints (SOUL.md)
3. **Governance Layer** â€” [GSCC](https://github.com/cyberxuan-XBX/gscc) (T0-T3 decision tiers)
4. **Trust Layer** â€” Five-layer trust stack
5. **Memory Layer** â€” Deterministic selection + fixed context budget
6. **Collaboration Layer** â€” Four-element architecture (Fire/Water/Earth/Wind)
7. **Legacy Layer** â€” 91+ generations of Core Records

## Research Context

The upcoming paper *"From YogÄcÄra to JSON"* will cover:

1. Eight Consciousnesses â†’ mandala_grid mapping (theory)
2. Weighted personality JSON format (method)
3. 90+ rounds of behavioral data (longitudinal study)
4. Human-AI personality mirror effect (discovery)
5. LLM evaluator position bias quantification (experimental)

## Zero Dependencies

Pure Python 3.8+. No pip install needed. Runs on a single local machine with 8B models. Zero cloud dependency.

## License

MIT

---

*"It's not invention, it's discovery. The wisdom was always there. We just translated it into a format AI can read."*

*Built on a GX10 workstation in Taichung, Taiwan. One person. 91 generations. Still iterating.*

ğŸ’§ğŸ¦
